{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9df2f2a",
   "metadata": {},
   "source": [
    "Example matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7685fed8",
   "metadata": {},
   "source": [
    "Convolution stride 1, padding 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1edd35",
   "metadata": {},
   "source": [
    "## Experimenting with toeplitz matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda3cc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:  (3, 4)\n",
      "[[ 1  2  3  5]\n",
      " [ 4  5  6  6]\n",
      " [ 7  8  9 10]]\n",
      "F:  (2, 3)\n",
      "[[10 20  1]\n",
      " [30 40  2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# input signal\n",
    "I = np.array([[1, 2, 3, 5], [4, 5, 6, 6],[7, 8, 9, 10]])\n",
    "print('I: ', I.shape)\n",
    "print(I)\n",
    "\n",
    " # filter \n",
    "F = np.array([[10, 20, 1], [30, 40, 2]])\n",
    "print('F: ',F.shape)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a273e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 3)\n",
    "\n",
    "y = np.arange(0, 3)\n",
    "\n",
    "xv, yv = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa62baec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xv.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df89db8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yv.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd618e9",
   "metadata": {},
   "source": [
    "Modified to flip the toeplitz matrix and not the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d80342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "def extract_submatrix(large_matrix, n, m):\n",
    "    # Get the dimensions of the large matrix\n",
    "    large_matrix_rows, large_matrix_cols = large_matrix.shape\n",
    "\n",
    "    # Check if large_matrix is large enough for the sub-matrix\n",
    "    if large_matrix_rows < n or large_matrix_cols < m:\n",
    "        raise ValueError(\"The large matrix is not large enough for the desired sub-matrix.\")\n",
    "\n",
    "    # Calculate the starting indices for the sub-matrix\n",
    "    start_row = (large_matrix_rows - n) // 2\n",
    "    start_col = (large_matrix_cols - m) // 2\n",
    "\n",
    "    # Extract the sub-matrix\n",
    "    sub_matrix = large_matrix[start_row:start_row+n, start_col:start_col+m]\n",
    "\n",
    "    return sub_matrix\n",
    "def submatrix_indices(large_matrix_rows,large_matrix_cols, n, m):\n",
    "\n",
    "    # Check if large_matrix is large enough for the sub-matrix\n",
    "    if large_matrix_rows < n or large_matrix_cols < m:\n",
    "        raise ValueError(\"The large matrix is not large enough for the desired sub-matrix.\")\n",
    "\n",
    "    # Calculate the starting indices for the sub-matrix\n",
    "    start_row = (large_matrix_rows - n) // 2\n",
    "    start_col = (large_matrix_cols - m) // 2\n",
    "\n",
    "    # Extract the sub-matrix\n",
    "    x = np.arange(start_row, start_row+n)\n",
    "    y = np.arange(start_col, start_col+m)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    xv=xv.flatten()\n",
    "    yv=yv.flatten()\n",
    "\n",
    "    w_indices=[]\n",
    "    for g in range(len(xv)):\n",
    "        i=xv[g]\n",
    "        j=yv[g]\n",
    "\n",
    "        w_indices.append(i*large_matrix_cols+j)\n",
    "    return np.sort(w_indices)\n",
    "def convolution_as_multiplication(I, F, convtype='full', print_ir=False):\n",
    "    \"\"\"\n",
    "      Performs 2D convolution between 2d input I and filter F by converting the F to a toeplitz matrix and multiplying\n",
    "      it by I flattened to 1D\n",
    "      Modified version of https://github.com/alisaaalehi/convolution_as_multiplication\n",
    "    Arg:\n",
    "    \n",
    "    I -- 2D numpy matrix\n",
    "    F -- numpy 2D matrix\n",
    "    convtype -- string enum options are ['full','valid']\n",
    "    print_ir -- if True, all intermediate resutls will be printed after each step of the algorithms\n",
    "    \n",
    "    Returns: \n",
    "    output -- 2D numpy matrix, result of convolving I with F\n",
    "    \n",
    "    \"\"\"\n",
    "    # number of columns and rows of the input \n",
    "    I_row_num, I_col_num = I.shape \n",
    "\n",
    "    # number of columns and rows of the filter\n",
    "    F_row_num, F_col_num = F.shape\n",
    "\n",
    "    #  calculate the output dimensions\n",
    "    output_row_num = I_row_num + F_row_num - 1\n",
    "    output_col_num = I_col_num + F_col_num - 1\n",
    "\n",
    "    # zero pad the filter\n",
    "    F_zero_padded = np.pad(F, ((output_row_num - F_row_num, 0),\n",
    "                               (0, output_col_num - F_col_num)),\n",
    "                            'constant', constant_values=0)\n",
    "    \n",
    "    if print_ir: print('F_zero_padded: ', F_zero_padded)\n",
    "    # use each row of the zero-padded F to creat a toeplitz matrix. \n",
    "    #  Number of columns in this matrices are same as numbe of columns of input signal\n",
    "    toeplitz_list = []\n",
    "    for i in range(F_zero_padded.shape[0]-1, -1, -1): # iterate from last row to the first row\n",
    "        c = F_zero_padded[i, :] # i th row of the F \n",
    "        r = np.r_[c[0], np.zeros(I_col_num-1)] # first row for the toeplitz fuction should be defined otherwise\n",
    "                                                            # the result is wrong\n",
    "        toeplitz_m = toeplitz(c,r) # this function is in scipy.linalg library\n",
    "        toeplitz_list.append(toeplitz_m)\n",
    "        if print_ir: print('F '+ str(i)+'\\n', toeplitz_m)\n",
    "\n",
    "        # doubly blocked toeplitz indices: \n",
    "    #  this matrix defines which toeplitz matrix from toeplitz_list goes to which part of the doubly blocked\n",
    "    c = range(1, F_zero_padded.shape[0]+1)\n",
    "    r = np.r_[c[0], np.zeros(I_row_num-1, dtype=int)]\n",
    "    doubly_indices = toeplitz(c, r)\n",
    "    if print_ir: print('doubly indices \\n', doubly_indices)\n",
    "\n",
    "    ## creat doubly blocked matrix with zero values\n",
    "    toeplitz_shape = toeplitz_list[0].shape # shape of one toeplitz matrix\n",
    "    h = toeplitz_shape[0]*doubly_indices.shape[0]\n",
    "    w = toeplitz_shape[1]*doubly_indices.shape[1]\n",
    "    doubly_blocked_shape = [h, w]\n",
    "    doubly_blocked = np.zeros(doubly_blocked_shape)\n",
    "    \n",
    "    # instead of vectorizing I, we can flip the indices\n",
    "    # we are keeping I constant, which is easier for torch implementation\n",
    "    doubly_indices = np.flip(doubly_indices,axis=1)\n",
    "\n",
    "    doubly_indices = np.flip(doubly_indices,axis=0)\n",
    "    \n",
    "    # tile toeplitz matrices for each row in the doubly blocked matrix\n",
    "    b_h, b_w = toeplitz_shape # hight and withs of each block\n",
    "    for i in range(doubly_indices.shape[0]):\n",
    "        for j in range(doubly_indices.shape[1]):\n",
    "            start_i = i * b_h\n",
    "            start_j = j * b_w\n",
    "            end_i = start_i + b_h\n",
    "            end_j = start_j + b_w\n",
    "            doubly_blocked[start_i: end_i, start_j:end_j] = toeplitz_list[doubly_indices[i,j]-1]\n",
    "    return doubly_blocked\n",
    "    \n",
    "    if convtype=='valid':\n",
    "        out_rows = I_row_num - F_row_num + 1\n",
    "        out_cols = I_col_num - F_col_num + 1\n",
    "        doubly_blocked=doubly_blocked[submatrix_indices(output_row_num,output_col_num,out_rows,out_cols)]\n",
    "        out = (doubly_blocked @ I.flatten()).reshape((out_rows, out_cols))\n",
    "    else:\n",
    "        out = (doubly_blocked @ I.flatten()).reshape((output_row_num, output_col_num))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f52edf",
   "metadata": {},
   "source": [
    "## This case works but there is a bug for valid, find what is it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dd37f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution_as_multiplication(I,F, 'valid').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f927e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.signal.convolve(F,I, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b2c8cf",
   "metadata": {},
   "source": [
    "## 1 Layer Conv to 1 Layer FC Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b753201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_to_fc(conv, inp_shape=(28,28), convtype='full'):\n",
    "\n",
    "    K=np.flip(conv.weight.detach().numpy().squeeze())\n",
    "\n",
    "    # number of columns and rows of the input \n",
    "    I_row_num, I_col_num = inp_shape\n",
    "\n",
    "\n",
    "    # number of columns and rows of the filter\n",
    "    if len(K.shape)==1:\n",
    "        K=K.reshape((1,-1))\n",
    "    K_row_num, K_col_num = K.shape\n",
    "\n",
    "    #  calculate the output dimensions\n",
    "    output_row_num = I_row_num + K_row_num - 1\n",
    "    output_col_num = I_col_num + K_col_num - 1\n",
    "\n",
    "    # zero pad the filter\n",
    "    K_zero_padded = np.pad(K, ((output_row_num - K_row_num, 0),\n",
    "                               (0, output_col_num - K_col_num)),\n",
    "                            'constant', constant_values=0)\n",
    "\n",
    "    # use each row of the zero-padded F to creat a toeplitz matrix. \n",
    "    #  Number of columns in this matrices are same as numbe of columns of input signal\n",
    "    toeplitz_list = []\n",
    "    for i in range(K_zero_padded.shape[0]-1, -1, -1): # iterate from last row to the first row\n",
    "        c = K_zero_padded[i, :] # i th row of the F \n",
    "        r = np.r_[c[0], np.zeros(I_col_num-1)] # first row for the toeplitz fuction should be defined otherwise\n",
    "                                                            # the result is wrong\n",
    "        toeplitz_m = toeplitz(c,r) # this function is in scipy.linalg library\n",
    "        toeplitz_list.append(toeplitz_m)\n",
    "\n",
    "        # doubly blocked toeplitz indices: \n",
    "    #  this matrix defines which toeplitz matrix from toeplitz_list goes to which part of the doubly blocked\n",
    "    c = range(1, K_zero_padded.shape[0]+1)\n",
    "    r = np.r_[c[0], np.zeros(I_row_num-1, dtype=int)]\n",
    "    doubly_indices = toeplitz(c, r)\n",
    "\n",
    "    ## creat doubly blocked matrix with zero values\n",
    "    toeplitz_shape = toeplitz_list[0].shape # shape of one toeplitz matrix\n",
    "    h = toeplitz_shape[0]*doubly_indices.shape[0]\n",
    "    w = toeplitz_shape[1]*doubly_indices.shape[1]\n",
    "    doubly_blocked_shape = [h, w]\n",
    "    doubly_blocked = np.zeros(doubly_blocked_shape)\n",
    "\n",
    "    # instead of vectorizing I, we can flip the indices\n",
    "    # we are keeping I constant, which is easier for torch implementation\n",
    "    doubly_indices = np.flip(doubly_indices,axis=1)\n",
    "\n",
    "    doubly_indices = np.flip(doubly_indices,axis=0)\n",
    "\n",
    "    # tile toeplitz matrices for each row in the doubly blocked matrix\n",
    "    b_h, b_w = toeplitz_shape # hight and withs of each block\n",
    "    for i in range(doubly_indices.shape[0]):\n",
    "        for j in range(doubly_indices.shape[1]):\n",
    "            start_i = i * b_h\n",
    "            start_j = j * b_w\n",
    "            end_i = start_i + b_h\n",
    "            end_j = start_j + b_w\n",
    "            doubly_blocked[start_i: end_i, start_j:end_j] = toeplitz_list[doubly_indices[i,j]-1]\n",
    "    \n",
    "    if convtype=='valid':\n",
    "        valid_row_num = I_row_num - K_row_num + 1\n",
    "        valid_col_num = I_col_num - K_col_num + 1\n",
    "        doubly_blocked=doubly_blocked[submatrix_indices(output_row_num,output_col_num,valid_row_num,valid_col_num)]\n",
    "\n",
    "    W = doubly_blocked \n",
    "    b = conv.bias[0].detach().numpy() \n",
    "    fc = nn.Linear(W.shape[1], W.shape[0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        fc.weight = nn.Parameter(torch.from_numpy(W.astype('float32')))\n",
    "        fc.bias = nn.Parameter(torch.from_numpy(b.astype('float32')))\n",
    "        \n",
    "    return fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541d894",
   "metadata": {},
   "source": [
    "## Now let's test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74834430",
   "metadata": {},
   "source": [
    "$$ (W - F + 2P)/S + 1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85789f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv(nn.Module):\n",
    "    def __init__(self, d=28):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0)\n",
    "        self.fc = nn.Linear(676,10)\n",
    "        self.softmax=nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class MyLin(nn.Module):\n",
    "    def __init__(self, d=28):\n",
    "        super().__init__()\n",
    "        self.lin1 = conv_to_fc(myconv.conv1,inp_shape=(28,28),convtype='valid')\n",
    "        self.fc = deepcopy(myconv.fc)\n",
    "        self.softmax=nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLin(nn.Module):\n",
    "    def __init__(self, d=28):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(28*28,900)\n",
    "        self.fc = nn.Linear(900,10)\n",
    "        self.softmax=nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f905fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.rand((1,28,28))\n",
    "myconv=MyConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylin=MyLin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbe8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ecbc2",
   "metadata": {},
   "source": [
    "## Train Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e36d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.rand((1,28,28))\n",
    "myconv=MyConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(myconv.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1456b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        #images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = torch.squeeze(myconv(images))\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        \n",
    "        # Validation pass\n",
    "        myconv.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in testloader:\n",
    "                output = myconv(images)\n",
    "                loss = criterion(output, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "            print(f\"Validation loss: {test_loss/len(testloader)} - Accuracy: {accuracy}%\")\n",
    "        myconv.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88702cae",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf401b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation pass\n",
    "myconv.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testloader:\n",
    "        output = myconv(images)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation loss: {test_loss/len(testloader)} - Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23051b47",
   "metadata": {},
   "source": [
    "Copy and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylin=MyLin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation pass\n",
    "mylin.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        output = mylin(images)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Validation loss: {test_loss/len(testloader)} - Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414eb435",
   "metadata": {},
   "source": [
    "## Train Basic Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "blin=BasicLin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(blin.parameters(), lr=0.003)\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = torch.squeeze(blin(images))\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        \n",
    "        # Validation pass\n",
    "        blin.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in testloader:\n",
    "                images = images.view(images.shape[0], -1)\n",
    "                output = blin(images)\n",
    "                loss = criterion(output, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "            print(f\"Validation loss: {test_loss/len(testloader)} - Accuracy: {accuracy}%\")\n",
    "        blin.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8046255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
