{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40db2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ac7b8",
   "metadata": {},
   "source": [
    "Focus on K=100, L=28 (2 dim), M=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b3442",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c9c0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, d=28):\n",
    "        super().__init__()\n",
    "        #W\n",
    "        self.lin1 = nn.Linear(28*28,100)\n",
    "        #V fix it to 1/100\n",
    "        self.lin2 = nn.Linear(1,100)\n",
    "        self.lin2.weight.data=torch.ones(1,100)/100\n",
    "        self.lin2.bias.data = torch.zeros(1)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = torch.erf(x / torch.sqrt(torch.tensor(2.0)))\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f73a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv(nn.Module):\n",
    "    def __init__(self, d=28):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=5, stride=3, padding=2,\n",
    "                              padding_mode='circular')\n",
    "        self.fc = nn.Linear(100,1)\n",
    "        self.softmax=nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "650be646",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcf855e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = MyConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "291b66d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7a2e2c4a0cdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'inw' is not defined"
     ]
    }
   ],
   "source": [
    "conv(torch.unsqueeze(torch.unsqueeze(inw,0),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "W=fc.lin1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2780e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.std(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/(28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959fd7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPR(w):\n",
    "    return torch.sum(w**4)/(torch.sum(w**2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c66f7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPR(w):\n",
    "    return torch.sum(w**4)/(torch.sum(w**2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db7999a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_fields(W):\n",
    "    \"\"\"\n",
    "    W - K x (NxN) matrix\n",
    "        K number of linear units\n",
    "        NxN shape of the image\n",
    "    \"\"\"\n",
    "    K,N_squared = W.shape\n",
    "    N = int(np.sqrt(N_squared))\n",
    "    for i in range(K):\n",
    "        print(IPR(W[i]))\n",
    "        plt.imshow(W[i].reshape((N,N)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#W=fc.lin1.weight.data\n",
    "#visualize_fields(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf21e4a0",
   "metadata": {},
   "source": [
    "For binary discrimination tasks, we used {âˆ’1, +1} output for the two classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927f48b",
   "metadata": {},
   "source": [
    "## DATA\n",
    "non-Gaussian, higher-order local structure\n",
    "of the inputs,\n",
    "\n",
    "\n",
    "math.erf(x)\n",
    "\n",
    "\n",
    "$\\epsilon^{-}=2.8$\n",
    "\n",
    "\n",
    "$\\epsilon^{+}=5.6$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae0f20",
   "metadata": {},
   "source": [
    "Now I got some ok results for\n",
    "\n",
    "$\\epsilon^{+} = 5.6$\n",
    "$\\epsilon^{-} = 1$\n",
    "$ gain factor=5 $\n",
    "\n",
    "sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf79f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# define functions\n",
    "vec_erf = np.vectorize(math.erf)\n",
    "psi = lambda z: vec_erf(z/(np.sqrt(2)))\n",
    "\n",
    "gain_factor=5\n",
    "normalizer = np.sqrt(2/np.pi * np.arcsin(gain_factor**2/(1+gain_factor**2)))\n",
    "epsilon_plus=5.6\n",
    "epsilon_minus=5\n",
    "img_size = 28\n",
    "mean_vector = np.zeros(img_size)\n",
    "positive_cov_matrix = np.ones((img_size,img_size))\n",
    "negative_cov_matrix = np.ones((img_size,img_size))\n",
    "\n",
    "# Generate a random vector\n",
    "#random_vector = np.random.multivariate_normal(mean_vector, cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "45f5a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(img_size):\n",
    "    for j in range(img_size):\n",
    "        positive_cov_matrix[i,j] = np.exp(- ( np.abs(i-j) / epsilon_plus)**2 )\n",
    "positive_cov_matrix=np.kron(positive_cov_matrix,positive_cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e3346509",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(img_size):\n",
    "    for j in range(img_size):\n",
    "        negative_cov_matrix[i,j] = np.exp(- ( np.abs(i-j) / epsilon_minus)**2 )\n",
    "negative_cov_matrix=np.kron(negative_cov_matrix,negative_cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f4a5916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_positive_example(n=10000):\n",
    "#     z_mu = np.random.multivariate_normal(np.ones(784), positive_cov_matrix,n)\n",
    "#     nlgp_z = psi(gain_factor * z_mu)/normalizer\n",
    "#     return nlgp_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3125cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_negative_example(n=10000):\n",
    "#     z_mu = np.random.multivariate_normal(np.ones(784), negative_cov_matrix,n)\n",
    "#     nlgp_z = psi(gain_factor * z_mu)/normalizer\n",
    "#     return nlgp_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "be3eef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_online_batch(n=1000):\n",
    "    #np.random.random()\n",
    "    positive_size=int(0.5*n)\n",
    "    negative_size=n-positive_size\n",
    "    \n",
    "    z_mu_pos = np.random.multivariate_normal(np.zeros(img_size**2), positive_cov_matrix,positive_size)\n",
    "    positive_dataset = psi(gain_factor * z_mu_pos)/normalizer\n",
    "    \n",
    "    z_mu_neg = np.random.multivariate_normal(np.zeros(img_size**2), negative_cov_matrix,negative_size)\n",
    "    negative_dataset = psi(gain_factor * z_mu_neg)/normalizer\n",
    "    \n",
    "    batch = torch.from_numpy(np.vstack([negative_dataset, positive_dataset]).astype(np.float32))\n",
    "    batch_labels = torch.from_numpy(np.array([-1]*negative_size + [1]*positive_size).astype('float32'))\n",
    "    # shuffle \n",
    "    shuf_idx= torch.randperm(n)\n",
    "    batch=batch[shuf_idx]\n",
    "    batch_labels=batch_labels[shuf_idx]\n",
    "    return batch, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dfcac6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, b_labels = get_online_batch(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1b57169b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batch[np.where(b_labels==-1)[0][4]].reshape(28, 28))\n",
    "plt.savefig(\"g5ep5.png\",dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1147830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a8a0ab6520>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batch[np.where(b_labels==1)[0][10]].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ca469",
   "metadata": {},
   "source": [
    "## Train the net: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(fc.parameters(), lr=0.05, momentum=0.9)\n",
    "#optimizer = torch.optim.Adam(fc.parameters(), lr=0.001)\n",
    "num_epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_IPR(W):\n",
    "    return (torch.sum(W**4,dim=1)/(torch.sum(W**2, dim=1))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f61fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_IPR=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    \n",
    "    inputs, labels = get_online_batch(1000)\n",
    "    out = fc(inputs)\n",
    "    loss = mse(out.squeeze(), labels)\n",
    "    \n",
    "    ## Backwards pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Train MSE is {loss}\\n')\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        with torch.no_grad():\n",
    "            test_dataset, test_labels=get_online_batch(10000)\n",
    "            test_outs = fc(test_dataset)\n",
    "            accuracy = torch.sum( test_outs.sign().squeeze() == test_labels)/len(test_labels)\n",
    "            print(f\"Accuracy is {accuracy}\")\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W=fc.lin1.weight.data\n",
    "visualize_fields(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1726261",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W[-8].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0072ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(F.softmax(W[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11298da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_IPR=np.array(save_IPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    plt.plot(np.arange(save_IPR.shape[0]),save_IPR[:,i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9816bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_IPR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_IPR[10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b52fcf",
   "metadata": {},
   "source": [
    "## Train Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65904b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = MyConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48904723",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(conv.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = torch.optim.Adam(fc.parameters(), lr=0.001)\n",
    "num_epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232260bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    \n",
    "    inputs, labels = batch_sample(1000)\n",
    "    inputs = inputs.reshape(1000,1,28,28)\n",
    "    out = conv(inputs)\n",
    "    loss = mse(out.squeeze(), labels)\n",
    "    \n",
    "    ## Backwards pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'MSE is {loss}\\n')\n",
    "    accuracy = torch.sum( out.sign().squeeze() == labels)\n",
    "    print(f\"Accuracy is {accuracy}\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004457e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d91b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class MyLin(nn.Module):\n",
    "    def __init__(self, d=28):\n",
    "        super().__init__()\n",
    "        self.lin1 = conv_to_fc(conv.conv1)\n",
    "        self.fc = deepcopy(conv.fc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = MyLin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6104ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W=ml.lin1.weight.data\n",
    "visualize_fields(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb94189",
   "metadata": {},
   "source": [
    "## Compute Cumulants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "879beb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5159282",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = get_online_batch(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0f8134e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, b_labels = sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a099ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_batch = batch.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "70c36794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np_batch=np_batch[b_labels==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "48c83e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_matrix =np.mean(np_batch,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f2f701d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_per_pixel = np.zeros((img_size**2,len(np_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b36d638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(img_size**2):\n",
    "    var_per_pixel[i] = np_batch[:,i] - mean_matrix[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b8d7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_mat = np.zeros((img_size**2,img_size**2,img_size**2,img_size**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2eb56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "for gain_factor in [0.1, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 6, 8 ,10 ]:\n",
    "    # define functions\n",
    "    vec_erf = np.vectorize(math.erf)\n",
    "    psi = lambda z: vec_erf(z/(np.sqrt(2)))\n",
    "\n",
    "    #gain_factor=0.5\n",
    "    normalizer = np.sqrt(2/np.pi * np.arcsin(gain_factor**2/(1+gain_factor**2)))\n",
    "    epsilon_plus=5.6\n",
    "    epsilon_minus=2.8 \n",
    "    img_size = 100\n",
    "    mean_vector = np.zeros(img_size)\n",
    "    positive_cov_matrix = np.ones((img_size,img_size))\n",
    "    negative_cov_matrix = np.ones((img_size,img_size))\n",
    "\n",
    "    # Generate a random vector\n",
    "    #random_vector = np.random.multivariate_normal(mean_vector, cov_matrix)\n",
    "    for i in range(img_size):\n",
    "        for j in range(img_size):\n",
    "            positive_cov_matrix[i,j] = np.exp(- ( np.abs(i-j) / epsilon_plus)**2 )\n",
    "    \n",
    "    for i in range(img_size):\n",
    "        for j in range(img_size):\n",
    "            negative_cov_matrix[i,j] = np.exp(- ( np.abs(i-j) / epsilon_minus)**2 )\n",
    "    \n",
    "    def get_online_batch(n=1000):\n",
    "        #np.random.random()\n",
    "        positive_size=int(0.5*n)\n",
    "        negative_size=n-positive_size\n",
    "\n",
    "        z_mu_pos = np.random.multivariate_normal(np.ones(img_size), positive_cov_matrix,positive_size)\n",
    "        positive_dataset = psi(gain_factor * z_mu_pos)/normalizer\n",
    "\n",
    "        z_mu_neg = np.random.multivariate_normal(np.ones(img_size), negative_cov_matrix,negative_size)\n",
    "        negative_dataset = psi(gain_factor * z_mu_neg)/normalizer\n",
    "\n",
    "        batch = torch.from_numpy(np.vstack([negative_dataset, positive_dataset]).astype(np.float32))\n",
    "        batch_labels = torch.from_numpy(np.array([-1]*negative_size + [1]*positive_size).astype('float32'))\n",
    "        # shuffle \n",
    "        shuf_idx= torch.randperm(n)\n",
    "        batch=batch[shuf_idx]\n",
    "        batch_labels=batch_labels[shuf_idx]\n",
    "        return batch, batch_labels\n",
    "\n",
    "    sample_dataset = get_online_batch(10000)\n",
    "    batch, b_labels = sample_dataset\n",
    "    batch=batch[b_labels==1]\n",
    "    cnt+=1\n",
    "    np.save(f\"tilepos{cnt}.npy\",batch.detach().numpy())\n",
    "    b_labels=b_labels[b_labels==1]\n",
    "#     np_batch = batch.detach().numpy()\n",
    "#     mean_matrix =np.mean(np_batch,axis=0)\n",
    "#     var_per_pixel = np.zeros((img_size,len(np_batch)))\n",
    "\n",
    "#     for i in range(img_size):\n",
    "#         var_per_pixel[i] = np_batch[:,i] - mean_matrix[i]\n",
    "\n",
    "#     cum_mat = np.zeros((img_size,img_size,img_size,img_size))\n",
    "\n",
    "\n",
    "#     for i in tqdm(range(img_size)):\n",
    "#         for j in range(img_size):\n",
    "#             for k in range(img_size):\n",
    "#                 for l in range(img_size):\n",
    "#                     cum_mat[i,j,k,l] = np.sum(var_per_pixel[i] * var_per_pixel[j] * var_per_pixel[k] * var_per_pixel[l])/(len(np_batch)-1) - \\\n",
    "#                         np.sum(var_per_pixel[i]*var_per_pixel[j])/(len(np_batch)-1) * np.sum(var_per_pixel[k]*var_per_pixel[l])/(len(np_batch)-1) - \\\n",
    "#                         np.sum(var_per_pixel[i]*var_per_pixel[k])/(len(np_batch)-1) * np.sum(var_per_pixel[j]*var_per_pixel[l])/(len(np_batch)-1) - \\\n",
    "#                         np.sum(var_per_pixel[i]*var_per_pixel[l])/(len(np_batch)-1) * np.sum(var_per_pixel[j]*var_per_pixel[k])/(len(np_batch)-1)\n",
    "\n",
    "\n",
    "#     tensor = tl.tensor(cum_mat)\n",
    "#     factors = parafac(tensor, rank=1)\n",
    "#     factor_matrices = factors.factors\n",
    "#     print(IPR(torch.from_numpy(factor_matrices[0].astype(np.float32))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "69ced466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 100])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31bf1ef",
   "metadata": {},
   "source": [
    "Problems: \n",
    "Check means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "55387163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39039608017110133"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(var_per_pixel[i]*var_per_pixel[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48dbadec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3983633471133586"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(var_per_pixel[i],var_per_pixel[j])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "94a3b168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3983633471133587"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_value(var_per_pixel[i],var_per_pixel[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "78ffaa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_value(x,y):\n",
    "\n",
    "\tmean_x = sum(x) / float(len(x))\n",
    "\tmean_y = sum(y) / float(len(y))\n",
    "\n",
    "\tsub_x = [i - mean_x for i in x]\n",
    "\tsub_y = [i - mean_y for i in y]\n",
    "\n",
    "\tsum_value = sum([sub_y[i]*sub_x[i] for i in range(len(x))])\n",
    "\tdenom = float(len(x)-1)\n",
    "\n",
    "\tcov = sum_value/denom\n",
    "\treturn cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3f047b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 6., 5.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in tqdm(range(img_size**2)):\n",
    "    for j in range(img_size**2):\n",
    "        for k in range(img_size**2):\n",
    "            for l in range(img_size**2):\n",
    "                cum_mat[i,j,k,l] = np.mean(var_per_pixel[i] * var_per_pixel[j] * var_per_pixel[k] * var_per_pixel[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7eec9ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0421)\n"
     ]
    }
   ],
   "source": [
    "    tensor = tl.tensor(cum_mat)\n",
    "    factors = parafac(tensor, rank=1)\n",
    "    factor_matrices = factors.factors\n",
    "    print(IPR(torch.from_numpy(factor_matrices[0].astype(np.float32))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ebcc3",
   "metadata": {},
   "source": [
    "0.0416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43e0a586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_batch.mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c2f3ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39039608017110133"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(var_per_pixel[i]*var_per_pixel[j]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb423175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4560093787338222"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(var_per_pixel[i],var_per_pixel[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bdf518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
